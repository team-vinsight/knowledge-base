# CuVSLAM

Paper - [arxiv.org/pdf/2506.04359](https://arxiv.org/pdf/2506.04359)

GitHub Repo - <https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_visual_slam>

Official Documentation - [cuVSLAM — isaac_ros_docs documentation](https://nvidia-isaac-ros.github.io/concepts/visual_slam/cuvslam/index.html)



# PyCuVSLAM

GitHub Repo - [github.com/NVlabs/PyCuVSLAM](https://github.com/NVlabs/PyCuVSLAM)

Documentation - [Welcome to PyCuVSLAM’s documentation! — PyCuVSLAM documentation](https://nvlabs.github.io/PyCuVSLAM/index.html)

Tutorials and Forums

<https://wiki.seeedstudio.com/pycuvslam_recomputer_robotics/>

<https://forums.developer.nvidia.com/t/pycuvslam-in-aerial-outdoor-environment/342176>

## 

# YouTube

<https://www.youtube.com/watch?v=ImaltGOlEDc>

Demonstration of my VSLAM UAV pipeline using Isaac ROS Visual SLAM. Code: <https://github.com/bandofpv/VSLAM-UAV>... Note: The motion capture cameras visible in the video are used solely for ground truth pose validation. The UAV relies entirely on visual-inertial odometry (VIO) and the flight controller's IMU, fused through an Extended Kalman Filter (EKF), for local pose estimation during flight.

<https://www.andrewbernas.com/docs/tutorials/robots/vslam>
